#!/usr/bin/env python3
"""
Computationally Intensive Research Tasks for Z Framework Empirical Validation
============================================================================

Self-contained, step-by-step protocol for computationally intensive validations
implementing TC01-TC05 test cases as specified. Assumes no prior knowledge.

The Z Framework unifies physical and discrete domains via invariant c.
In discrete domains, primes are modeled as low-curvature geodesics.
Tests extend to N up to 10^10 and prioritize empirical rigor.

Test Cases:
TC01: Scale-invariant validation of ~15% prime density enhancement across N
TC02: Parameter optimization: grid-search k for clustering variance and asymmetry
TC03: Zeta zeros embedding: helical correlation between primes and unfolded zeta zeros
TC04: Control sequences: confirm specificity via non-prime controls
TC05: Asymptotic hypothesis test: validate convergence in sparse regimes with dynamic k

Each test runs 3x for stability, bootstrap CIs are computed.
"""

import os
import sys
import time
import logging
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

import numpy as np
import scipy.stats as stats
from scipy.optimize import minimize_scalar
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Headless backend
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import sympy as sp
import mpmath as mp

# High precision settings
mp.mp.dps = 50
PHI = (1 + mp.sqrt(5)) / 2
E_SQUARED = mp.exp(2)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('computational_validation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ComputationalValidator:
    """
    Main validator class implementing TC01-TC05 test protocols.
    """
    
    def __init__(self, max_n: int = 10**6, bootstrap_samples: int = 1000):
        """
        Initialize validator with computational parameters.
        
        Args:
            max_n: Maximum N for prime generation (scaled progressively)
            bootstrap_samples: Number of bootstrap samples for CI computation
        """
        self.max_n = max_n
        self.bootstrap_samples = bootstrap_samples
        self.results = {}
        
        logger.info(f"Initialized ComputationalValidator with max_N={max_n}")
        
    def bootstrap_ci(self, data: np.ndarray, confidence: float = 0.95) -> Tuple[float, float]:
        """
        Compute bootstrap confidence interval.
        
        Args:
            data: Sample data
            confidence: Confidence level (default 0.95)
            
        Returns:
            Tuple of (lower_bound, upper_bound)
        """
        n = len(data)
        bootstrap_means = []
        
        for _ in range(self.bootstrap_samples):
            sample = np.random.choice(data, size=n, replace=True)
            bootstrap_means.append(np.mean(sample))
            
        alpha = 1 - confidence
        lower = np.percentile(bootstrap_means, 100 * alpha / 2)
        upper = np.percentile(bootstrap_means, 100 * (1 - alpha / 2))
        
        return lower, upper
    
    def generate_primes(self, n: int) -> List[int]:
        """Generate primes up to n using sympy."""
        try:
            return [p for p in range(2, n + 1) if sp.isprime(p)]
        except Exception as e:
            logger.error(f"Error generating primes up to {n}: {e}")
            return []
    
    def golden_ratio_transform(self, numbers: List[int], k: float) -> np.ndarray:
        """
        Apply golden ratio curvature transformation θ'(n,k) = φ * ((n mod φ)/φ)^k
        
        Args:
            numbers: List of integers to transform
            k: Curvature parameter
            
        Returns:
            Transformed values
        """
        phi_float = float(PHI)
        transformed = []
        
        for n in numbers:
            residue = n % phi_float
            normalized = residue / phi_float
            transformed_val = phi_float * (normalized ** k)
            transformed.append(transformed_val)
            
        return np.array(transformed)
    
    def compute_density_enhancement(self, primes: List[int], integers: List[int], 
                                  k: float, num_bins: int = 20) -> Dict[str, Any]:
        """
        Compute prime density enhancement for given k.
        
        Args:
            primes: List of prime numbers
            integers: List of all integers in range
            k: Curvature parameter
            num_bins: Number of histogram bins
            
        Returns:
            Dictionary with enhancement metrics
        """
        try:
            # Transform both sets
            theta_primes = self.golden_ratio_transform(primes, k)
            theta_integers = self.golden_ratio_transform(integers, k)
            
            # Create bins
            phi_float = float(PHI)
            bin_edges = np.linspace(0, phi_float, num_bins + 1)
            
            # Compute densities
            hist_primes, _ = np.histogram(theta_primes, bins=bin_edges, density=True)
            hist_integers, _ = np.histogram(theta_integers, bins=bin_edges, density=True)
            
            # Avoid division by zero
            hist_integers = np.maximum(hist_integers, 1e-10)
            
            # Compute enhancements
            enhancements = (hist_primes - hist_integers) / hist_integers * 100
            valid_enhancements = enhancements[np.isfinite(enhancements)]
            
            if len(valid_enhancements) == 0:
                return {'max_enhancement': 0.0, 'mean_enhancement': 0.0, 'std_enhancement': 0.0}
            
            return {
                'max_enhancement': np.max(valid_enhancements),
                'mean_enhancement': np.mean(valid_enhancements),
                'std_enhancement': np.std(valid_enhancements),
                'enhancements': valid_enhancements
            }
            
        except Exception as e:
            logger.error(f"Error computing density enhancement for k={k}: {e}")
            return {'max_enhancement': 0.0, 'mean_enhancement': 0.0, 'std_enhancement': 0.0}
    
    def compute_zeta_zeros(self, num_zeros: int) -> List[float]:
        """Compute Riemann zeta zeros using mpmath."""
        zeros = []
        try:
            for i in range(1, num_zeros + 1):
                zero = mp.zetazero(i)
                zeros.append(float(mp.im(zero)))
        except Exception as e:
            logger.error(f"Error computing zeta zeros: {e}")
        return zeros
    
    def helical_embedding_correlation(self, primes: List[int], zeros: List[float]) -> float:
        """
        Compute correlation between primes and zeta zeros in helical embedding.
        
        Returns:
            Pearson correlation coefficient
        """
        try:
            # Take minimum length to ensure equal arrays
            min_len = min(len(primes), len(zeros))
            if min_len < 10:
                return 0.0
                
            primes_subset = primes[:min_len]
            zeros_subset = zeros[:min_len]
            
            # Simple embedding: use log-scaled positions
            prime_coords = np.log(np.array(primes_subset) + 1)
            zero_coords = np.array(zeros_subset)
            
            # Compute correlation
            correlation, p_value = stats.pearsonr(prime_coords, zero_coords)
            
            return correlation if np.isfinite(correlation) else 0.0
            
        except Exception as e:
            logger.error(f"Error computing helical correlation: {e}")
            return 0.0
    
    def tc01_scale_invariant_validation(self) -> Dict[str, Any]:
        """
        TC01: Scale-invariant validation of ~15% prime density enhancement across N.
        Tests enhancement consistency across different scales.
        """
        logger.info("Starting TC01: Scale-invariant validation")
        
        scales = [10**3, 10**4, 10**5, min(10**6, self.max_n)]
        k_optimal = 0.3  # Expected optimal from literature
        results = {'scales': scales, 'enhancements': [], 'confidence_intervals': []}
        
        for n in scales:
            logger.info(f"TC01: Processing scale N={n}")
            
            # Generate data
            primes = self.generate_primes(n)
            integers = list(range(2, n + 1))
            
            if len(primes) < 10:
                logger.warning(f"Too few primes for N={n}, skipping")
                continue
            
            # Run multiple times for stability
            enhancements = []
            for run in range(3):
                enhancement_data = self.compute_density_enhancement(primes, integers, k_optimal)
                enhancements.append(enhancement_data['max_enhancement'])
            
            # Compute statistics
            mean_enhancement = np.mean(enhancements)
            ci_lower, ci_upper = self.bootstrap_ci(np.array(enhancements))
            
            results['enhancements'].append(mean_enhancement)
            results['confidence_intervals'].append((ci_lower, ci_upper))
            
            logger.info(f"TC01: N={n}, Enhancement={mean_enhancement:.1f}%, CI=[{ci_lower:.1f}%, {ci_upper:.1f}%]")
        
        # Check scale invariance (enhancement should be relatively stable)
        if len(results['enhancements']) > 1:
            enhancement_stability = np.std(results['enhancements'])
            results['scale_invariance_metric'] = enhancement_stability
            results['passes_scale_invariance'] = enhancement_stability < 5.0  # Threshold
        else:
            results['scale_invariance_metric'] = float('inf')
            results['passes_scale_invariance'] = False
        
        logger.info(f"TC01 Complete: Scale invariance metric = {results.get('scale_invariance_metric', 'N/A')}")
        return results
    
    def tc02_parameter_optimization(self) -> Dict[str, Any]:
        """
        TC02: Parameter optimization via grid-search k for clustering variance and asymmetry.
        """
        logger.info("Starting TC02: Parameter optimization")
        
        n = min(10**5, self.max_n)  # Use manageable size for optimization
        primes = self.generate_primes(n)
        integers = list(range(2, n + 1))
        
        if len(primes) < 50:
            logger.error("TC02: Insufficient primes for optimization")
            return {'optimal_k': 0.3, 'max_enhancement': 0.0}
        
        # Grid search over k values
        k_values = np.arange(0.1, 1.0, 0.05)
        results = {'k_values': k_values, 'enhancements': [], 'variances': []}
        
        for k in k_values:
            # Run multiple times for stability
            k_enhancements = []
            for run in range(3):
                enhancement_data = self.compute_density_enhancement(primes, integers, k)
                k_enhancements.append(enhancement_data['max_enhancement'])
            
            mean_enhancement = np.mean(k_enhancements)
            variance = np.var(k_enhancements)
            
            results['enhancements'].append(mean_enhancement)
            results['variances'].append(variance)
        
        # Find optimal k (maximize enhancement, minimize variance)
        enhancements = np.array(results['enhancements'])
        variances = np.array(results['variances'])
        
        # Combined score: enhancement - penalty for variance
        scores = enhancements - 0.1 * variances
        optimal_idx = np.argmax(scores)
        optimal_k = k_values[optimal_idx]
        max_enhancement = enhancements[optimal_idx]
        
        results['optimal_k'] = optimal_k
        results['max_enhancement'] = max_enhancement
        results['optimization_score'] = scores[optimal_idx]
        
        logger.info(f"TC02 Complete: Optimal k={optimal_k:.3f}, Enhancement={max_enhancement:.1f}%")
        return results
    
    def tc03_zeta_zeros_embedding(self) -> Dict[str, Any]:
        """
        TC03: Zeta zeros embedding with helical correlation between primes and unfolded zeta zeros.
        """
        logger.info("Starting TC03: Zeta zeros embedding")
        
        n = min(10**4, self.max_n)  # Smaller scale for zeta computation
        num_zeros = min(100, n // 100)  # Reasonable number of zeros
        
        primes = self.generate_primes(n)
        zeros = self.compute_zeta_zeros(num_zeros)
        
        if len(primes) < 10 or len(zeros) < 10:
            logger.error("TC03: Insufficient data for correlation analysis")
            return {'correlation': 0.0, 'p_value': 1.0}
        
        # Run correlation analysis multiple times
        correlations = []
        p_values = []
        
        for run in range(3):
            correlation = self.helical_embedding_correlation(primes, zeros)
            correlations.append(correlation)
            
            # Compute p-value (simplified)
            min_len = min(len(primes), len(zeros))
            if min_len > 10:
                t_stat = correlation * np.sqrt((min_len - 2) / (1 - correlation**2))
                p_value = 2 * (1 - stats.t.cdf(abs(t_stat), min_len - 2))
                p_values.append(p_value)
        
        results = {
            'correlations': correlations,
            'mean_correlation': np.mean(correlations),
            'correlation_stability': np.std(correlations),
            'p_values': p_values,
            'mean_p_value': np.mean(p_values) if p_values else 1.0
        }
        
        # Check if correlation is significant
        results['significant_correlation'] = results['mean_correlation'] > 0.5 and results['mean_p_value'] < 0.05
        
        logger.info(f"TC03 Complete: Correlation={results['mean_correlation']:.3f}, p={results['mean_p_value']:.3e}")
        return results
    
    def tc04_control_sequences(self) -> Dict[str, Any]:
        """
        TC04: Control sequences to confirm specificity via non-prime controls.
        """
        logger.info("Starting TC04: Control sequences")
        
        n = min(10**5, self.max_n)
        k = 0.3  # Use expected optimal
        
        # Generate test sequences
        primes = self.generate_primes(n)
        composites = [i for i in range(4, n + 1) if not sp.isprime(i)][:len(primes)]  # Match length
        random_sequence = np.random.randint(2, n, size=len(primes)).tolist()
        integers = list(range(2, min(2 + len(primes), n + 1)))
        
        sequences = {
            'primes': primes,
            'composites': composites,
            'random': random_sequence
        }
        
        results = {}
        
        for seq_name, sequence in sequences.items():
            if len(sequence) < 10:
                continue
                
            # Run enhancement analysis
            seq_enhancements = []
            for run in range(3):
                enhancement_data = self.compute_density_enhancement(sequence, integers, k)
                seq_enhancements.append(enhancement_data['max_enhancement'])
            
            results[seq_name] = {
                'enhancements': seq_enhancements,
                'mean_enhancement': np.mean(seq_enhancements),
                'std_enhancement': np.std(seq_enhancements)
            }
        
        # Check specificity (primes should have higher enhancement)
        if 'primes' in results and 'composites' in results:
            prime_enhancement = results['primes']['mean_enhancement']
            composite_enhancement = results['composites']['mean_enhancement']
            results['specificity_ratio'] = prime_enhancement / max(composite_enhancement, 0.1)
            results['passes_specificity'] = results['specificity_ratio'] > 1.2
        else:
            results['specificity_ratio'] = 1.0
            results['passes_specificity'] = False
        
        logger.info(f"TC04 Complete: Specificity ratio={results.get('specificity_ratio', 'N/A'):.2f}")
        return results
    
    def tc05_asymptotic_hypothesis_test(self) -> Dict[str, Any]:
        """
        TC05: Asymptotic hypothesis test to validate convergence in sparse regimes with dynamic k.
        """
        logger.info("Starting TC05: Asymptotic hypothesis test")
        
        # Test convergence across increasing scales
        scales = [10**3, 10**4, min(10**5, self.max_n)]
        k_values = np.arange(0.2, 0.5, 0.1)  # Dynamic k testing
        
        results = {'scales': scales, 'k_values': k_values, 'convergence_data': []}
        
        for n in scales:
            logger.info(f"TC05: Testing convergence at N={n}")
            
            primes = self.generate_primes(n)
            integers = list(range(2, n + 1))
            
            if len(primes) < 20:
                continue
            
            scale_results = {'n': n, 'k_enhancements': {}}
            
            for k in k_values:
                # Multiple runs for stability
                k_enhancements = []
                for run in range(3):
                    enhancement_data = self.compute_density_enhancement(primes, integers, k)
                    k_enhancements.append(enhancement_data['max_enhancement'])
                
                scale_results['k_enhancements'][k] = {
                    'mean': np.mean(k_enhancements),
                    'std': np.std(k_enhancements)
                }
            
            results['convergence_data'].append(scale_results)
        
        # Analyze convergence
        if len(results['convergence_data']) >= 2:
            # Check if enhancement values stabilize across scales
            convergence_metrics = []
            for k in k_values:
                k_means = []
                for scale_data in results['convergence_data']:
                    if k in scale_data['k_enhancements']:
                        k_means.append(scale_data['k_enhancements'][k]['mean'])
                
                if len(k_means) >= 2:
                    convergence_metric = np.std(k_means) / max(np.mean(k_means), 0.1)
                    convergence_metrics.append(convergence_metric)
            
            results['convergence_score'] = np.mean(convergence_metrics) if convergence_metrics else float('inf')
            results['passes_convergence'] = results['convergence_score'] < 0.5  # Threshold
        else:
            results['convergence_score'] = float('inf')
            results['passes_convergence'] = False
        
        logger.info(f"TC05 Complete: Convergence score={results.get('convergence_score', 'N/A'):.3f}")
        return results
    
    def run_comprehensive_validation(self) -> Dict[str, Any]:
        """
        Run all test cases TC01-TC05 and compile comprehensive results.
        """
        logger.info("=== Starting Comprehensive Computational Validation ===")
        start_time = time.time()
        
        comprehensive_results = {
            'metadata': {
                'start_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'max_n': self.max_n,
                'bootstrap_samples': self.bootstrap_samples,
                'mpmath_precision': mp.mp.dps
            },
            'test_results': {}
        }
        
        # Run each test case
        test_cases = [
            ('TC01', self.tc01_scale_invariant_validation),
            ('TC02', self.tc02_parameter_optimization),
            ('TC03', self.tc03_zeta_zeros_embedding),
            ('TC04', self.tc04_control_sequences),
            ('TC05', self.tc05_asymptotic_hypothesis_test)
        ]
        
        for test_name, test_function in test_cases:
            logger.info(f"\n{'='*50}")
            logger.info(f"Executing {test_name}")
            logger.info(f"{'='*50}")
            
            try:
                test_start = time.time()
                result = test_function()
                test_duration = time.time() - test_start
                
                result['duration_seconds'] = test_duration
                result['status'] = 'COMPLETED'
                comprehensive_results['test_results'][test_name] = result
                
                logger.info(f"{test_name} completed in {test_duration:.2f} seconds")
                
            except Exception as e:
                logger.error(f"Error in {test_name}: {e}")
                comprehensive_results['test_results'][test_name] = {
                    'status': 'FAILED',
                    'error': str(e),
                    'duration_seconds': 0
                }
        
        # Compile summary
        total_duration = time.time() - start_time
        comprehensive_results['metadata']['total_duration'] = total_duration
        comprehensive_results['metadata']['end_time'] = time.strftime('%Y-%m-%d %H:%M:%S')
        
        # Generate summary statistics
        summary = self._generate_summary(comprehensive_results)
        comprehensive_results['summary'] = summary
        
        logger.info(f"\n{'='*60}")
        logger.info("COMPREHENSIVE VALIDATION COMPLETE")
        logger.info(f"Total Duration: {total_duration:.2f} seconds")
        logger.info(f"Tests Passed: {summary['tests_passed']}/{summary['total_tests']}")
        logger.info(f"{'='*60}")
        
        return comprehensive_results
    
    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate summary statistics from comprehensive results."""
        test_results = results['test_results']
        
        completed_tests = [name for name, result in test_results.items() 
                          if result.get('status') == 'COMPLETED']
        failed_tests = [name for name, result in test_results.items() 
                       if result.get('status') == 'FAILED']
        
        # Determine pass/fail for each test based on specific criteria
        test_passes = {}
        
        # TC01: Pass if scale invariance is achieved
        if 'TC01' in test_results and test_results['TC01'].get('status') == 'COMPLETED':
            test_passes['TC01'] = test_results['TC01'].get('passes_scale_invariance', False)
        
        # TC02: Pass if reasonable enhancement found
        if 'TC02' in test_results and test_results['TC02'].get('status') == 'COMPLETED':
            test_passes['TC02'] = test_results['TC02'].get('max_enhancement', 0) > 5.0
        
        # TC03: Pass if significant correlation found
        if 'TC03' in test_results and test_results['TC03'].get('status') == 'COMPLETED':
            test_passes['TC03'] = test_results['TC03'].get('significant_correlation', False)
        
        # TC04: Pass if specificity achieved
        if 'TC04' in test_results and test_results['TC04'].get('status') == 'COMPLETED':
            test_passes['TC04'] = test_results['TC04'].get('passes_specificity', False)
        
        # TC05: Pass if convergence demonstrated
        if 'TC05' in test_results and test_results['TC05'].get('status') == 'COMPLETED':
            test_passes['TC05'] = test_results['TC05'].get('passes_convergence', False)
        
        summary = {
            'total_tests': len(test_results),
            'completed_tests': len(completed_tests),
            'failed_tests': len(failed_tests),
            'tests_passed': sum(test_passes.values()),
            'test_pass_details': test_passes,
            'overall_success_rate': sum(test_passes.values()) / max(len(test_passes), 1),
            'completed_test_names': completed_tests,
            'failed_test_names': failed_tests
        }
        
        return summary


def main():
    """Main execution function."""
    print("Z Framework: Computationally Intensive Research Tasks")
    print("=" * 60)
    
    # Initialize validator with manageable scale for testing
    # Note: Can be scaled up to 10^10 for full validation
    validator = ComputationalValidator(max_n=10**6, bootstrap_samples=100)
    
    # Run comprehensive validation
    results = validator.run_comprehensive_validation()
    
    # Save results
    output_file = 'computational_validation_results.json'
    try:
        import json
        with open(output_file, 'w') as f:
            # Convert numpy types to native Python types for JSON serialization
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.bool_):
                    return bool(obj)
                elif isinstance(obj, dict):
                    return {key: convert_numpy(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(item) for item in obj]
                else:
                    return obj
            
            json.dump(convert_numpy(results), f, indent=2)
        print(f"\nResults saved to: {output_file}")
    except Exception as e:
        print(f"Error saving results: {e}")
    
    # Display key findings
    summary = results.get('summary', {})
    print(f"\n=== VALIDATION SUMMARY ===")
    print(f"Tests Completed: {summary.get('completed_tests', 0)}/{summary.get('total_tests', 0)}")
    print(f"Tests Passed: {summary.get('tests_passed', 0)}")
    print(f"Success Rate: {summary.get('overall_success_rate', 0):.1%}")
    
    if summary.get('test_pass_details'):
        print(f"\nDetailed Results:")
        for test_name, passed in summary['test_pass_details'].items():
            status = "PASS" if passed else "FAIL"
            print(f"  {test_name}: {status}")
    
    return results


if __name__ == "__main__":
    main()