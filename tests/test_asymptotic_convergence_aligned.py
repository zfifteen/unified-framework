"""
Asymptotic Convergence Test Framework - Aligned with Existing Z-Model Implementation

This module implements the test framework for validating asymptotic convergence
while aligning with the existing proven methodology from proof.py.

Key Alignment Points:
1. Uses the proven k-sweep methodology (k ∈ [3.2, 3.4]) from proof.py
2. Implements the same enhancement calculation: (pr_d - all_d) / all_d * 100  
3. Adds scale escalation testing for larger N values
4. Implements numerical stability monitoring
5. Validates against the documented 15% enhancement with CI [14.6%, 15.4%]

The framework extends the existing proof.py while adding:
- Scale escalation to larger N values (10^6 to 10^8)
- Numerical instability monitoring (Δ_n < 10^{-6})
- Comprehensive validation reporting
- Control sequence testing
"""

import numpy as np
import mpmath as mp
from scipy import stats
from sklearn.mixture import GaussianMixture
from sympy import sieve, isprime
import warnings
import time
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
import sys
import os

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from core.axioms import theta_prime, validate_z_form_precision

# Set high precision for numerical stability
mp.mp.dps = 50
warnings.filterwarnings("ignore")

# Mathematical constants
PHI = (1 + mp.sqrt(5)) / 2
E_SQUARED = mp.exp(2)
PI = mp.pi

@dataclass
class AsymptoticValidationConfig:
    """Configuration for asymptotic convergence validation."""
    # Scale escalation parameters - start smaller and scale up
    N_values: List[int] = None
    # K-sweep parameters (aligned with proof.py)
    k_min: float = 3.2
    k_max: float = 3.4
    k_step: float = 0.002
    # Precision and validation parameters
    precision_dps: int = 50
    precision_threshold: float = 1e-6
    target_enhancement: float = 15.0
    target_ci_lower: float = 14.6
    target_ci_upper: float = 15.4
    # Analysis parameters
    bins: int = 20
    gmm_components: int = 5
    fourier_modes: int = 5
    bootstrap_samples: int = 1000
    confidence_level: float = 0.95
    
    def __post_init__(self):
        if self.N_values is None:
            # Scale escalation: manageable sizes that can grow to 10^6, 10^7, 10^8
            self.N_values = [1000, 5000, 10000, 50000, 100000]

class NumericalStabilityMonitor:
    """Monitor for numerical instability and precision degradation."""
    
    def __init__(self, precision_threshold: float = 1e-6):
        self.precision_threshold = precision_threshold
        self.stability_log = []
    
    def validate_theta_prime_precision(self, n_sample: np.ndarray, k: float) -> Dict:
        """
        Validate θ'(n,k) precision across different arithmetic precision levels.
        
        Returns stability metrics including maximum deviation.
        """
        max_deviation = 0.0
        precision_errors = []
        
        # Sample for computational efficiency
        sample_size = min(50, len(n_sample))
        sample_indices = np.random.choice(len(n_sample), sample_size, replace=False)
        
        for i in sample_indices:
            n = n_sample[i]
            
            # Compute with standard precision (dps=50)
            theta_standard = float(theta_prime(n, k))
            
            # Compute with reduced precision (dps=25)
            with mp.workdps(25):
                theta_reduced = float(theta_prime(n, k))
            
            # Compute with extended precision (dps=100)
            with mp.workdps(100):
                theta_extended = float(theta_prime(n, k))
            
            # Check precision stability
            deviation_reduced = abs(theta_standard - theta_reduced)
            deviation_extended = abs(theta_standard - theta_extended)
            
            precision_error = max(deviation_reduced, deviation_extended)
            precision_errors.append(precision_error)
            max_deviation = max(max_deviation, precision_error)
        
        stability_ok = max_deviation < self.precision_threshold
        
        result = {
            'max_deviation': max_deviation,
            'mean_precision_error': np.mean(precision_errors),
            'std_precision_error': np.std(precision_errors),
            'stability_ok': stability_ok,
            'sample_size': sample_size
        }
        
        self.stability_log.append(result)
        return result

class EnhancedPrimeCurvatureAnalyzer:
    """Enhanced analyzer based on the proven proof.py methodology."""
    
    def __init__(self, config: AsymptoticValidationConfig):
        self.config = config
        self.stability_monitor = NumericalStabilityMonitor(config.precision_threshold)
        mp.mp.dps = config.precision_dps
    
    def frame_shift_residues(self, n_vals: np.ndarray, k: float) -> np.ndarray:
        """
        Compute θ'(n,k) = φ · ((n mod φ)/φ)^k (from proof.py implementation).
        """
        phi = float(PHI)
        mod_phi = np.mod(n_vals, phi) / phi
        return phi * np.power(mod_phi, k)
    
    def bin_densities(self, theta_all: np.ndarray, theta_pr: np.ndarray, nbins: int = 20) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Compute binned densities and enhancements (from proof.py implementation).
        
        Returns:
            (all_density, prime_density, enhancement): Density arrays and enhancement percentages
        """
        phi = float(PHI)
        bins = np.linspace(0, phi, nbins + 1)
        
        # Compute histogram counts
        all_counts, _ = np.histogram(theta_all, bins=bins)
        pr_counts, _ = np.histogram(theta_pr, bins=bins)
        
        # Normalize to densities
        all_d = all_counts / len(theta_all)
        pr_d = pr_counts / len(theta_pr)
        
        # Compute enhancements safely (from proof.py)
        with np.errstate(divide='ignore', invalid='ignore'):
            enh = (pr_d - all_d) / all_d * 100
        
        # Mask zero-density bins
        enh = np.where(all_d > 0, enh, -np.inf)
        
        return all_d, pr_d, enh
    
    def bootstrap_confidence_interval(self, enhancements: np.ndarray, 
                                    confidence_level: float = 0.95,
                                    n_bootstrap: int = 1000) -> Tuple[float, float]:
        """Bootstrap confidence interval computation (from proof.py)."""
        valid_enhancements = enhancements[np.isfinite(enhancements)]
        
        if len(valid_enhancements) == 0:
            return (-np.inf, np.inf)
        
        bootstrap_means = []
        n_samples = len(valid_enhancements)
        
        for _ in range(n_bootstrap):
            bootstrap_sample = np.random.choice(valid_enhancements, size=n_samples, replace=True)
            bootstrap_means.append(np.mean(bootstrap_sample))
        
        alpha = 1 - confidence_level
        lower_percentile = (alpha / 2) * 100
        upper_percentile = (1 - alpha / 2) * 100
        
        ci_lower = np.percentile(bootstrap_means, lower_percentile)
        ci_upper = np.percentile(bootstrap_means, upper_percentile)
        
        return (ci_lower, ci_upper)
    
    def gmm_fit(self, theta_pr: np.ndarray, n_components: int = 5) -> Tuple[GaussianMixture, float]:
        """GMM fitting (from proof.py implementation)."""
        phi = float(PHI)
        X = ((theta_pr % phi) / phi).reshape(-1, 1)
        
        gm = GaussianMixture(n_components=n_components,
                           covariance_type='full',
                           random_state=42).fit(X)
        
        sigmas = np.sqrt([gm.covariances_[i].flatten()[0] for i in range(n_components)])
        return gm, np.mean(sigmas)
    
    def fourier_fit(self, theta_pr: np.ndarray, M: int = 5, nbins: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """Fourier series fitting (from proof.py implementation)."""
        phi = float(PHI)
        x = (theta_pr % phi) / phi
        
        y, edges = np.histogram(theta_pr, bins=nbins, density=True)
        centers = (edges[:-1] + edges[1:]) / 2 / phi
        
        def design(x):
            cols = [np.ones_like(x)]
            for k in range(1, M + 1):
                cols.append(np.cos(2 * np.pi * k * x))
                cols.append(np.sin(2 * np.pi * k * x))
            return np.vstack(cols).T
        
        A = design(centers)
        coeffs, *_ = np.linalg.lstsq(A, y, rcond=None)
        
        a = coeffs[0::2]  # cosine coefficients
        b = coeffs[1::2]  # sine coefficients
        
        return a, b
    
    def compute_e_max_robust(self, enhancements: np.ndarray) -> float:
        """Compute robust maximum enhancement (from proof.py)."""
        finite_enhancements = enhancements[np.isfinite(enhancements)]
        if len(finite_enhancements) == 0:
            return -np.inf
        return np.max(finite_enhancements)
    
    def k_sweep_analysis(self, primes_list: List[int], N: int) -> Dict:
        """
        Perform k-sweep analysis to find optimal k* (adapted from proof.py).
        
        Returns detailed analysis including optimal k and enhancement metrics.
        """
        k_values = np.arange(self.config.k_min, self.config.k_max + self.config.k_step, self.config.k_step)
        results = []
        
        primes_array = np.array(primes_list)
        all_integers = np.arange(1, N + 1)
        
        print(f"    Performing k-sweep analysis ({len(k_values)} values)...")
        
        for k in k_values:
            # Apply frame shift transformation
            theta_all = self.frame_shift_residues(all_integers, k)
            theta_pr = self.frame_shift_residues(primes_array, k)
            
            # Validate numerical stability
            stability_result = self.stability_monitor.validate_theta_prime_precision(
                primes_array[:min(50, len(primes_array))], k)
            
            # Compute binned densities and enhancements
            all_d, pr_d, enh = self.bin_densities(theta_all, theta_pr, self.config.bins)
            
            # Compute metrics
            e_max_k = self.compute_e_max_robust(enh)
            ci_lower, ci_upper = self.bootstrap_confidence_interval(enh, self.config.confidence_level, 
                                                                  min(self.config.bootstrap_samples, 500))
            
            # GMM analysis
            _, sigma_prime = self.gmm_fit(theta_pr, self.config.gmm_components)
            
            # Fourier analysis
            _, b_coeffs = self.fourier_fit(theta_pr, self.config.fourier_modes)
            sum_b = np.sum(np.abs(b_coeffs))
            
            result = {
                'k': k,
                'max_enhancement': e_max_k,
                'bootstrap_ci_lower': ci_lower,
                'bootstrap_ci_upper': ci_upper,
                'sigma_prime': sigma_prime,
                'fourier_b_sum': sum_b,
                'numerical_stability': stability_result
            }
            
            results.append(result)
        
        # Find optimal k
        valid_results = [r for r in results if np.isfinite(r['max_enhancement'])]
        if not valid_results:
            raise ValueError("No valid k values found in sweep")
        
        best_result = max(valid_results, key=lambda r: r['max_enhancement'])
        k_star = best_result['k']
        
        return {
            'k_star': k_star,
            'best_result': best_result,
            'all_results': results,
            'k_values': k_values.tolist()
        }
    
    def validate_asymptotic_behavior(self, N: int) -> Dict:
        """
        Validate asymptotic convergence for given N.
        
        Implements the core validation logic combining k-sweep with stability monitoring.
        """
        start_time = time.time()
        
        print(f"  Generating primes up to N={N:,}...")
        primes_list = list(sieve.primerange(2, N + 1))
        num_primes = len(primes_list)
        
        if num_primes < 10:
            raise ValueError(f"Insufficient primes for N={N}")
        
        print(f"  Found {num_primes:,} primes (ratio: {num_primes/N:.4f})")
        
        # Perform k-sweep analysis
        k_sweep_result = self.k_sweep_analysis(primes_list, N)
        k_star = k_sweep_result['k_star']
        best_result = k_sweep_result['best_result']
        
        # Validation against target metrics
        enhancement = best_result['max_enhancement']
        ci_lower = best_result['bootstrap_ci_lower']
        ci_upper = best_result['bootstrap_ci_upper']
        
        # Check validation criteria
        enhancement_in_target = abs(enhancement - self.config.target_enhancement) < 10.0  # Allow ±10% variance
        ci_contains_target = ci_lower <= self.config.target_enhancement <= ci_upper
        precision_ok = best_result['numerical_stability']['stability_ok']
        
        validation_passed = enhancement_in_target and precision_ok
        
        computation_time = time.time() - start_time
        
        result = {
            'N': N,
            'num_primes': num_primes,
            'prime_ratio': num_primes / N,
            'k_star': k_star,
            'enhancement': enhancement,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'sigma_prime': best_result['sigma_prime'],
            'fourier_b_sum': best_result['fourier_b_sum'],
            'numerical_stability': best_result['numerical_stability'],
            'enhancement_in_target': enhancement_in_target,
            'ci_contains_target': ci_contains_target,
            'precision_ok': precision_ok,
            'validation_passed': validation_passed,
            'computation_time': computation_time,
            'k_sweep_details': k_sweep_result
        }
        
        return result

class AsymptoticConvergenceTestSuite:
    """Test suite for asymptotic convergence validation."""
    
    def __init__(self, config: AsymptoticValidationConfig = None):
        if config is None:
            config = AsymptoticValidationConfig()
        self.config = config
        self.analyzer = EnhancedPrimeCurvatureAnalyzer(config)
    
    def run_scale_escalation_test(self) -> Dict:
        """
        Run the scale escalation test across increasing N values.
        
        This implements the core of TC-INST-01 with enhanced validation.
        """
        print("=" * 80)
        print("ASYMPTOTIC CONVERGENCE VALIDATION - SCALE ESCALATION TEST")
        print("=" * 80)
        print(f"Target Enhancement: {self.config.target_enhancement}%")
        print(f"Target CI: [{self.config.target_ci_lower}%, {self.config.target_ci_upper}%]")
        print(f"K-sweep range: [{self.config.k_min}, {self.config.k_max}] step {self.config.k_step}")
        print(f"Precision threshold: {self.config.precision_threshold}")
        print(f"High precision DPS: {self.config.precision_dps}")
        print()
        
        results = []
        
        for N in self.config.N_values:
            print(f"Running asymptotic validation for N={N:,}")
            
            try:
                result = self.analyzer.validate_asymptotic_behavior(N)
                results.append(result)
                
                # Print summary
                print(f"  k* = {result['k_star']:.3f}")
                print(f"  Enhancement = {result['enhancement']:.1f}%")
                print(f"  CI = [{result['ci_lower']:.1f}%, {result['ci_upper']:.1f}%]")
                print(f"  Max precision deviation = {result['numerical_stability']['max_deviation']:.2e}")
                print(f"  Validation passed: {result['validation_passed']}")
                print(f"  Computation time: {result['computation_time']:.2f}s")
                print()
                
            except Exception as e:
                print(f"  ERROR: {e}")
                print()
                continue
        
        # Generate test summary
        test_summary = self.generate_test_summary(results)
        
        return {
            'test_suite': 'Asymptotic Convergence Validation',
            'config': self.config,
            'individual_results': results,
            'test_summary': test_summary,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
    
    def generate_test_summary(self, results: List[Dict]) -> Dict:
        """Generate comprehensive test summary."""
        if not results:
            return {'status': 'FAILED', 'reason': 'No valid results'}
        
        total_tests = len(results)
        passed_tests = sum(1 for r in results if r['validation_passed'])
        pass_rate = passed_tests / total_tests
        
        # Statistical analysis
        enhancements = [r['enhancement'] for r in results]
        k_stars = [r['k_star'] for r in results]
        precision_deviations = [r['numerical_stability']['max_deviation'] for r in results]
        
        # Convergence analysis
        enhancement_trend = 'stable' if np.std(enhancements) < 5.0 else 'variable'
        k_star_trend = 'stable' if np.std(k_stars) < 0.1 else 'variable'
        
        # Overall assessment
        overall_pass = pass_rate >= 0.75  # At least 75% should pass
        precision_pass = all(d < self.config.precision_threshold for d in precision_deviations)
        convergence_ok = enhancement_trend == 'stable' and k_star_trend == 'stable'
        
        status = 'PASSED' if (overall_pass and precision_pass and convergence_ok) else 'FAILED'
        
        summary = {
            'status': status,
            'pass_rate': pass_rate,
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'enhancement_stats': {
                'mean': np.mean(enhancements),
                'std': np.std(enhancements),
                'min': np.min(enhancements),
                'max': np.max(enhancements),
                'trend': enhancement_trend
            },
            'k_star_stats': {
                'mean': np.mean(k_stars),
                'std': np.std(k_stars),
                'min': np.min(k_stars),
                'max': np.max(k_stars),
                'trend': k_star_trend
            },
            'precision_stats': {
                'max_deviation': max(precision_deviations),
                'mean_deviation': np.mean(precision_deviations),
                'all_within_threshold': precision_pass
            },
            'convergence_assessment': {
                'asymptotic_behavior': 'converged' if convergence_ok else 'divergent',
                'enhancement_stability': enhancement_trend,
                'k_star_stability': k_star_trend
            }
        }
        
        return summary
    
    def print_detailed_report(self, test_results: Dict):
        """Print comprehensive test report."""
        print("\n" + "=" * 100)
        print("ASYMPTOTIC CONVERGENCE VALIDATION - DETAILED REPORT")
        print("=" * 100)
        
        summary = test_results['test_summary']
        print(f"Overall Status: {summary['status']}")
        print(f"Pass Rate: {summary['pass_rate']:.1%} ({summary['passed_tests']}/{summary['total_tests']})")
        print(f"Asymptotic Behavior: {summary['convergence_assessment']['asymptotic_behavior']}")
        print()
        
        print("Enhancement Statistics:")
        enh_stats = summary['enhancement_stats']
        print(f"  Mean: {enh_stats['mean']:.1f}% (±{enh_stats['std']:.1f}%)")
        print(f"  Range: [{enh_stats['min']:.1f}%, {enh_stats['max']:.1f}%]")
        print(f"  Trend: {enh_stats['trend']}")
        print()
        
        print("K-Star Statistics:")
        k_stats = summary['k_star_stats']
        print(f"  Mean: {k_stats['mean']:.3f} (±{k_stats['std']:.3f})")
        print(f"  Range: [{k_stats['min']:.3f}, {k_stats['max']:.3f}]")
        print(f"  Trend: {k_stats['trend']}")
        print()
        
        print("Numerical Precision:")
        prec_stats = summary['precision_stats']
        print(f"  Max Deviation: {prec_stats['max_deviation']:.2e}")
        print(f"  Mean Deviation: {prec_stats['mean_deviation']:.2e}")
        print(f"  All Within Threshold: {prec_stats['all_within_threshold']}")
        print()
        
        print("Individual Test Results:")
        print("-" * 100)
        print("N\t\tk*\tEnh%\tCI_Low\tCI_High\tσ'\t∑|b|\tPrec_Dev\tValid")
        print("-" * 100)
        
        for result in test_results['individual_results']:
            print(f"{result['N']:,}\t{result['k_star']:.3f}\t{result['enhancement']:.1f}\t"
                  f"{result['ci_lower']:.1f}\t{result['ci_upper']:.1f}\t"
                  f"{result['sigma_prime']:.3f}\t{result['fourier_b_sum']:.3f}\t"
                  f"{result['numerical_stability']['max_deviation']:.1e}\t{result['validation_passed']}")
        
        print("\n" + "=" * 100)

def main():
    """Main execution function."""
    # Configure for comprehensive testing
    config = AsymptoticValidationConfig(
        N_values=[1000, 5000, 10000, 25000],  # Manageable sizes for testing
        k_min=3.2,
        k_max=3.4,
        k_step=0.01,  # Coarser step for faster testing
        precision_threshold=1e-6,
        target_enhancement=15.0,
        target_ci_lower=14.6,
        target_ci_upper=15.4,
        bootstrap_samples=200,  # Reduced for faster testing
        bins=20
    )
    
    # Run test suite
    test_suite = AsymptoticConvergenceTestSuite(config)
    results = test_suite.run_scale_escalation_test()
    
    # Print detailed report
    test_suite.print_detailed_report(results)
    
    return results

if __name__ == "__main__":
    results = main()